# 算法面经：字节大模型Agent 11.16

## 一面

1. 请介绍 Transformer 的结构组成及各部分作用
2. 如何降低 Transformer 的计算复杂度？常见的稀疏注意力变体有哪些？
3. LoRA微调的原理是什么？秩 r 的选择会对模型表现产生什么影响？
4. kv cache是什么？为什么能极大地提升推理速度？
5. RAG的完整流程，构建向量检索库时如何处理时间衰减对召回的影响？
6. 微调时的训练数据是怎么构建的？如何保证样本多样性和质量？
7. 在 RAG+知识图谱的 Agent 系统中，知识图谱更新的机制是怎样的？是怎样保证实时性的？
8. 训练 LoRA 模型时，你是如何选择冻结层的？依据是什么？
9. 在高并发查询 Agent 系统中，你会如何优化召回和生成阶段的延迟？
10. 大规模 Agent 系统在多线程/多进程场景下的资源调度策略如何设计？
11. 如果你要在 GPU 资源有限的条件下同时提供推理和微调服务，如何做资源分配和任务调度以保证时延和吞吐？
12. **代码题**：lc15 三数之和

## 二面

1. 介绍下self-attention，计算其时间复杂度
2. 为什么要用multi-head attention？
3. PPO的clip机制？在线强化学习和离线强化学习有什么区别？RLHF是哪一种？
4. 为什么要用reference model? 为了解决什么问题？
5. 如何让多个agent协同工作的？举个具体的协同机制例子
6. 如果一个agent误判导致策略冲突，如何处理？
7. 有没有用到类似AutoGen或LangChain的框架？为什么选这个框架？
8. 你是怎么设计agent的记忆系统？
9. 长期记忆如何存储？如果历史记录量非常大，怎么优化查询效率？
10. 有没有做记忆衰退，避免旧数据干扰新任务？
11. 你们这种模块堆叠的架构是怎么设计视觉问答模块和动作模块的协同逻辑的？
12. human feedback是怎么被agent消化吸收的？有没有用rl进行策略更新？
13. 有没有做过模型压缩？比如在车载端或低端设备上的推理加速？
14. 如果量化后理解能力下降怎么办？怎么做精度补偿？
15. 你怎么处理响应速度与推理精度之间的tradeoff？是先召回再精排，还是单次生成？
16. 如果要做电商agent，你会选择哪些模态的信息作为输入？比如文本评论、图像、视频、购买记录？